{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc73148-0e42-44fc-8770-37cb4771d1ec",
   "metadata": {},
   "source": [
    "# Correcting the metadata\n",
    "\n",
    "There are a couple of issues with the metadata being mis-labeled, and this notebook just checks those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76d4efe2-f9e2-40b2-a959-d449c51994c0",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# there is a FutureWarning in sklearn StandardScalar which is really annoying. This ignores it.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27d3075e-e940-48fc-a057-159892a6b0ed",
   "metadata": {},
   "source": [
    "def read_taxonomy(tax_file, firstchar):\n",
    "    \"\"\"\n",
    "    Read the taxonomy file and return a data frame\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(tax_file, sep='\\t', compression='gzip')\n",
    "    df = df[df['taxonomy'].str.contains('k__Bacteria')]\n",
    "    df = df[~df['taxonomy'].str.endswith(f'{firstchar}__')]\n",
    "    df = df.set_index('taxonomy')\n",
    "    df.index = df.index.str.split(';').str[-1]\n",
    "    df = df.sort_index(axis=1)\n",
    "    return df\n",
    "\n",
    "def sorted_presence_absence(df1, df2, minrowsum=0, asc_sort=False):\n",
    "    \"\"\"\n",
    "    Join the two tables and return the sorted version\n",
    "    \"\"\"\n",
    "    # filter so we only include samples sequenced on both MGI and MinION\n",
    "    common_columns = df1.columns.intersection(df2.columns)\n",
    "    df1_both = df1[common_columns]\n",
    "    df2_both = df2[common_columns]\n",
    "    \n",
    "    # create a presence/absence matrix\n",
    "    df1_presence = (df1_both > 0).astype(int)\n",
    "    df2_presence = (df2_both > 0).astype(int)*2\n",
    "\n",
    "    # here we filter on the minimum number of columns each taxa is in if requested\n",
    "    if minrowsum > 0:\n",
    "        df1_presence = df1_presence.loc[df1_presence[df1_presence.sum(axis=1) > minrowsum].index]\n",
    "        df2_presence = df2_presence.loc[df2_presence[df2_presence.sum(axis=1) > (2 * minrowsum)].index]\n",
    "    \n",
    "    # combine the two matrices and sort them\n",
    "    both = df1_presence.add(df2_presence, fill_value=0)\n",
    "    sboth = both.loc[both.sum(axis=1).sort_values(ascending=asc_sort).index]\n",
    "    sboth = sboth.sort_index(axis=1) # sort by column names\n",
    "\n",
    "    return sboth"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb29f8d5-0dd8-437a-aa28-d4213f9a005e",
   "metadata": {},
   "source": [
    "corrections = {\n",
    "    \"MGI_ID\" : { \n",
    "        '1112926_20171212_S' : '1447437_20171212_S',\n",
    "        '1128691_20170206_S' : '1128691_20171206_S',\n",
    "        '1255498_20171212_S' : '1590009_20171212_S',\n",
    "        '1316979_20171215_S' : '1651490_20171215_S',\n",
    "        '1598281_20180508_S' : '1588281_20180508_S',\n",
    "        '1723809_20180227_S' : '1085876_20180227_S',\n",
    "        '649354_20170206_S' : '639354_20171206_S',\n",
    "        '652927_20180226_S' : '715927_20180226_S',\n",
    "        '658355_20180301_S' : '658355_20180327_S',\n",
    "        '777851_20170918_S' : '778851_20170918_S',\n",
    "        '788707_20181126_S' : '788707_20181129_S'\n",
    "    },\n",
    "    \"minion_ID\" : {\n",
    "        '1112926_20171212_S' : '1447437_20171212_S',\n",
    "        '1255498_20171212_S' : '1590009_20171212_S',\n",
    "        '1316979_20171215_S' : '1651490_20171215_S',\n",
    "        '1598281_20180508_S' : '1588281_20180508_S',\n",
    "        '698917_20190119_S' : '698917_20180119_S'\n",
    "        }\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575e1c9c-9dc8-45df-b89c-8ede58cc9687",
   "metadata": {},
   "source": [
    "tax='genus'\n",
    "# read the data \n",
    "mgi_df = read_taxonomy(f\"../MGI/Taxonomy/MGI_reads_{tax}.normalised.tsv.gz\", tax[0])\n",
    "min_df = read_taxonomy(f\"../MinION/Taxonomy/Minion_read_based_annotations_{tax}.normalised.tsv.gz\", tax[0])\n",
    "\n",
    "sequence_type = 'MGI_ID'\n",
    "print(\"Checking corrections keys\", file=sys.stderr)\n",
    "# check the columns\n",
    "for s in corrections[sequence_type]:\n",
    "    if s in mgi_df.columns:\n",
    "        print(f\"Old name:{s} in {sequence_type}\", file=sys.stderr)\n",
    "\n",
    "        \n",
    "sequence_type = 'minion_ID'\n",
    "print(\"Checking corrections keys\", file=sys.stderr)\n",
    "# check the columns\n",
    "for s in corrections[sequence_type]:\n",
    "    if s in min_df.columns:\n",
    "        print(f\"Old name:{s} in {sequence_type}\", file=sys.stderr)\n",
    "        \n",
    "mgi_df = mgi_df.rename(columns=corrections['MGI_ID'])\n",
    "min_df = min_df.rename(columns=corrections['minion_ID'])\n",
    "\n",
    "#df = mgi_df.T\n",
    "df = min_df.T\n",
    "df.head()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "387e00dc-b37f-49a7-a360-93e88584f93a",
   "metadata": {},
   "source": [
    "print(\", \".join(list(df.index)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55bac4b2-aca6-4774-9089-202ea6217d00",
   "metadata": {},
   "source": [
    "# Load metadata table\n",
    "# This is generic so we can copy/paste. Yes, it should be a function, but its not.\n",
    "\n",
    "# metadata = pd.read_csv(\"../Metadata/Metadata20241026.txt\", encoding='utf-8', sep=\"\\t\", index_col=0)\n",
    "metadata = pd.read_csv(\"../Metadata/Metadata.txt\", encoding='windows-1252', sep=\"\\t\", index_col=0)\n",
    "metadata = metadata[~metadata[sequence_type].isna()]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0768c0c7-2336-4996-8607-432f317c3409",
   "metadata": {},
   "source": [
    "print(\", \".join(list(metadata.index)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0dce5a3-9f81-4151-9eb7-f1b4d1f5be44",
   "metadata": {},
   "source": [
    "s='623361_20180123_S'\n",
    "metadata.loc[s,]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93efcabc-4c09-466d-b3bd-1a43dd5013cb",
   "metadata": {},
   "source": [
    "\n",
    "# check the names before we replace them\n",
    "for s in corrections['MGI_ID']:\n",
    "    if s in set(metadata[sequence_type].values):\n",
    "        print(f\"{s} in MGI Metadata\", file=sys.stderr)\n",
    "\n",
    "\n",
    "\n",
    "for ix in metadata.index:\n",
    "    s = metadata.loc[ix, sequence_type]\n",
    "    if s in corrections[sequence_type]:\n",
    "        metadata.loc[ix, sequence_type] = corrections[sequence_type][s]\n",
    "\n",
    "todrop = []\n",
    "for s in metadata[sequence_type].values:\n",
    "    if s not in df.index:\n",
    "        print(f\"ERROR: {s} not found in data frame, dropped from metadata\", file=sys.stderr)\n",
    "        todrop.append(s)\n",
    "\n",
    "metadata.drop(todrop, inplace=True)\n",
    "\n",
    "todrop = []\n",
    "for s in df.index:\n",
    "    if not metadata[sequence_type].str.contains(s).any():\n",
    "        print(f\"ERROR: {s} not found in metadata, dropped from dataframe\", file=sys.stderr)\n",
    "        todrop.append(s)\n",
    "df.drop(todrop, inplace=True)\n",
    "        \n",
    "if metadata.shape[0] != df.shape[0]:\n",
    "    print(f\"ERROR: we have {metadata.shape[0]} rows in metadata and {df.shape[0]} data rows\", file=sys.stderr)\n",
    "metadata.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d30ff3-9439-4068-b601-8b3ffa0a43f3",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24e3f3-e027-4262-8b5c-74274a391c01",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioinfieConda",
   "language": "python",
   "name": "bioinfieconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
